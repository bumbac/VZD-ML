{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Úkol č. 2 - předzpracování dat a binární klasifikace (do 2. listopadu 23:59)\n",
    "\n",
    "  * V rámci tohoto úkolu se musíte vypořádat s příznaky, které jsou různých typů.\n",
    "  * Před tím, než na nich postavíte predikční model, je třeba je nějakým způsobem převést do číselné reprezentace.\n",
    "    \n",
    "> **Úkoly jsou zadány tak, aby Vám daly prostor pro invenci. Vymyslet _jak přesně_ budete úkol řešit, je důležitou součástí zadání a originalita či nápaditost bude také hodnocena!**\n",
    "\n",
    "## Zdroj dat\n",
    "\n",
    "Budeme se zabývat predikcí přežití pasažérů Titaniku.\n",
    "K dispozici máte trénovací data v souboru **data.csv** a data na vyhodnocení v souboru **evaluation.csv**.\n",
    "\n",
    "#### Seznam příznaků:\n",
    "* survived - zda přežil, 0 = Ne, 1 = Ano, **vysvětlovaná proměnná**, kterou chcete predikovat\n",
    "* pclass - Třída lodního lístku, 1 = první, 2 = druhá, 3 = třetí\n",
    "* name - jméno\n",
    "* sex - pohlaví\n",
    "* age - věk v letech\n",
    "* sibsp\t- počet sourozenců / manželů, manželek na palubě\n",
    "* parch - počet rodičů / dětí na palubě\n",
    "* ticket - číslo lodního lístku\n",
    "* fare - cena lodního lístku\n",
    "* cabin\t- číslo kajuty\n",
    "* embarked\t- místo nalodění, C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "* home.dest - Bydliště/Cíl\n",
    "\n",
    "## Pokyny k vypracování\n",
    "\n",
    "**Základní body zadání**, za jejichž (poctivé) vypracování získáte **8 bodů**:\n",
    "  * V Jupyter notebooku načtěte data ze souboru **data.csv**. Vhodným způsobem si je rozdělte na podmnožiny vhodné k trénování modelu.\n",
    "  * Projděte si jednotlivé příznaky a transformujte je do vhodné podoby pro použití ve vybraném klasifikačním modelu.\n",
    "  * Podle potřeby si můžete vytvářet nové příznaky (na základě existujících), například tedy můžete vytvořit příznak měřící délku jména. Některé příznaky můžete také úplně zahodit.\n",
    "  * Nějakým způsobem se vypořádejte s chybějícími hodnotami.\n",
    "  * Následně si vyberte vhodný klasifikační model z přednášek. Najděte vhodné hyperparametry a určete jeho přesnost (accuracy) na trénovací množině. Také určete jeho přesnost na testovací množině.\n",
    "  * Načtěte vyhodnocovací data ze souboru **evaluation.csv**. Napočítejte predikce pro tyto data (vysvětlovaná proměnná v nich již není). Vytvořte **results.csv** soubor, ve kterém tyto predikce uložíte do dvou sloupců: ID, predikce přežití. Tento soubor nahrajte do repozitáře.\n",
    "  * Ukázka prvních řádků souboru *results.csv*:\n",
    "  \n",
    "```\n",
    "ID,survived\n",
    "1000,0\n",
    "1001,1\n",
    "...\n",
    "```\n",
    "\n",
    "**Další body zadání** za případné další body  (můžete si vybrat, maximum bodů za úkol je každopádně 12 bodů):\n",
    "  * (až +4 body) Aplikujte všechny klasifikační modely z přednášek a určete (na základě přesnosti na validační množině), který je nejlepší. Přesnost tohoto nejlepšího modelu odhadněte pomocí křížové validace. K predikcím na vyhodnocovacích datech využijte tento model.\n",
    "  * (až +4 body) Zkuste použít nějaké (alespoň dvě) netriviální metody doplňování chybějících hodnot u věku. Zaměřte na vliv těchto metod na přesnost predikce výsledného modelu. K predikcím na vyhodnocovacích datech využijte ten přístup, který Vám vyjde jako nejlepší.\n",
    "\n",
    "## Poznámky k odevzdání\n",
    "\n",
    "  * Řiďte se pokyny ze stránky https://courses.fit.cvut.cz/BI-VZD/homeworks/index.html.\n",
    "  * Odevzdejte nejen Jupyter Notebook, ale i _csv_ soubor s predikcemi pro vyhodnocovací data (`results.csv`).\n",
    "  * Opravující Vám může umožnit úkol dodělat či opravit a získat tak další body. První verze je ale důležitá a bude-li odbytá, budete za to penalizováni**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn import metrics, datasets\n",
    "from sklearn.model_selection import ParameterGrid, train_test_split, KFold, LeaveOneOut\n",
    "from sklearn.neighbors import KNeighborsRegressor, KNeighborsClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with dropping of columns:\n",
    "\n",
    "ID, represents the order of person\n",
    "\n",
    "ticket, shows structure in which the tickets were sold, does not show the quality of person\n",
    "\n",
    "cabin - too many missing values (more than 3/4 are missing), too variable as well\n",
    "\n",
    "home.dest - does not represent any quality and has a lot of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df_eval = pd.read_csv('evaluation.csv')\n",
    "dflist = [df, df_eval]\n",
    "for d in dflist:\n",
    "    d.drop(columns=['ID', 'ticket', 'cabin', 'home.dest'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bruteforce cleaning of one row in fare in evaluation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = df_eval[df_eval['pclass'] == 3].fare.median()\n",
    "for index, row in df_eval.iterrows():\n",
    "    if np.isnan(row['fare']):\n",
    "        df_eval.at[index, 'fare'] = median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add auxiliary column - represents the length of name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in dflist:\n",
    "    name_l = []\n",
    "    for i in d['name']:\n",
    "        name_l.append(len(i))\n",
    "    d['name_length'] = name_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract rank/title of person from names - people with higher ranks have priority.\n",
    "rank is method of dataframe, use ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for d in dflist:\n",
    "    d['ranking'] = d.name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
    "    d['ranking'] = d['ranking'].replace(['Countess', 'Master', 'Jonkheer','Rev', 'Don', 'Dona', 'Lady', 'Sir', 'Dr'], 'noble')\n",
    "    d['ranking'] = d['ranking'].replace(['Major','Col', 'Capt'], 'army')\n",
    "    d['ranking'] = d['ranking'].replace('Ms', 'Mrs')\n",
    "    d['ranking'] = d['ranking'].replace('Mlle', 'Mrs')\n",
    "    d['ranking'] = d['ranking'].replace('Mme', 'Mrs')\n",
    "    # lower number is lower priority of saving \n",
    "    order = {\"army\": 1, \"Mr\": 2,  \"Mrs\": 3, \"noble\": 4}\n",
    "    d['ranking'] = d['ranking'].map(order)\n",
    "    d['ranking'] = d['ranking'].fillna(0)\n",
    "    d.drop(columns=['name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one-hot encoding for categoric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_to_category = ['sex', 'embarked']\n",
    "df = pd.get_dummies(df, columns=columns_to_category) \n",
    "df_eval = pd.get_dummies(df_eval, columns=columns_to_category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Age is the only column with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "survived         0\n",
       "pclass           0\n",
       "sex              0\n",
       "age            203\n",
       "sibsp            0\n",
       "parch            0\n",
       "fare             0\n",
       "embarked         2\n",
       "name_length      0\n",
       "ranking          0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pclass          0\n",
       "sex             0\n",
       "age            60\n",
       "sibsp           0\n",
       "parch           0\n",
       "fare            0\n",
       "embarked        0\n",
       "name_length     0\n",
       "ranking         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for d in dflist:\n",
    "    display(d.isna().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data for adding missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics as metrics\n",
    "import time\n",
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "rd_seed = 934\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=rd_seed)\n",
    "Xtrain, Xval, ytrain, yval = train_test_split(Xtrain, ytrain, test_size=0.2, random_state=rd_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS 2:\n",
    "Use kNN for filling missing values to 'age' column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "param_grid = {\n",
    "    'n_neighbors': range(1,12), \n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': range(1,3),\n",
    "    'n_jobs': [-1],\n",
    "    'algorithm': ['ball_tree', 'kd_tree', 'brute']\n",
    "}\n",
    "param_comb = ParameterGrid(param_grid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I only use Xtrain set for training the prediction of missing age -  the other sets Xval, Xtest are not affected by this prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in predicting missing age:  11.526424622962903\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(algorithm='brute', n_jobs=-1, n_neighbors=8)"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err = []\n",
    "Xnotnull = Xtrain.dropna().copy(deep=True)\n",
    "Xvalnotnull = Xval.dropna().copy(deep=True)\n",
    "XtrainKNN = Xnotnull.drop(columns=['age'])\n",
    "ytrainKNN = Xnotnull.age\n",
    "for param in param_comb:\n",
    "    XtrainKNN = Xnotnull.drop(columns=['age'])\n",
    "    ytrainKNN = Xnotnull.age\n",
    "    XvalKNN = Xvalnotnull.drop(columns=['age'])\n",
    "    yvalKNN = Xvalnotnull.age\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    XtrainKNN = pd.DataFrame(scaler.fit_transform(XtrainKNN), index=XtrainKNN.index, columns=XtrainKNN.columns)\n",
    "    XvalKNN = pd.DataFrame(scaler.transform(XvalKNN), index=XvalKNN.index, columns=XvalKNN.columns)\n",
    "\n",
    "    model = KNeighborsRegressor(**param)\n",
    "    model.fit(XtrainKNN, ytrainKNN)\n",
    "  \n",
    "    err.append(np.sqrt(metrics.mean_squared_error(yvalKNN, model.predict(XvalKNN))))\n",
    "best_index = np.argmin(err)\n",
    "best_param_missing = param_comb[best_index]\n",
    "print(\"Error in predicting missing age: \", err[best_index])\n",
    "missing_model = KNeighborsRegressor(**best_param_missing)\n",
    "missing_model.fit(XtrainKNN, ytrainKNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Found the best parameters for predicting missing values. Generate missing values for train and validate dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass         640\n",
       "age            640\n",
       "sibsp          640\n",
       "parch          640\n",
       "fare           640\n",
       "name_length    640\n",
       "ranking        640\n",
       "sex_female     640\n",
       "sex_male       640\n",
       "embarked_C     640\n",
       "embarked_Q     640\n",
       "embarked_S     640\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pclass         160\n",
       "age            160\n",
       "sibsp          160\n",
       "parch          160\n",
       "fare           160\n",
       "name_length    160\n",
       "ranking        160\n",
       "sex_female     160\n",
       "sex_male       160\n",
       "embarked_C     160\n",
       "embarked_Q     160\n",
       "embarked_S     160\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# predict\n",
    "X = Xtrain[Xtrain.age.isna()].drop(columns='age')\n",
    "Xv = Xval[Xval.age.isna()].drop(columns='age')\n",
    "predicted = missing_model.predict(X)\n",
    "predictedv = missing_model.predict(Xv)\n",
    "cnt = 0\n",
    "for index, row in Xtrain.iterrows():\n",
    "    if np.isnan(row['age']):\n",
    "        Xtrain.at[index, 'age'] = predicted[cnt]\n",
    "        cnt += 1\n",
    "cnt = 0\n",
    "for index, row in Xval.iterrows():\n",
    "    if np.isnan(row['age']):\n",
    "        Xval.at[index, 'age'] = predictedv[cnt]\n",
    "        cnt += 1\n",
    "# no missing data\n",
    "display(Xtrain.notnull().sum(axis=0))\n",
    "display(Xval.notnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "param_grid_train = {\n",
    "    'max_depth': range(1,25), \n",
    "    'criterion': ['entropy', 'gini'],\n",
    "    'splitter': ['best', 'random'],\n",
    "    'min_samples_leaf': range(2,5)\n",
    "}\n",
    "param_comb_train = ParameterGrid(param_grid_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ = []\n",
    "for param in param_comb_train:\n",
    "    model = DecisionTreeClassifier(**param)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    succ.append(metrics.accuracy_score(yval, model.predict(Xval)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training success: 0.8125\n",
      "params:  {'splitter': 'random', 'min_samples_leaf': 4, 'max_depth': 11, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=11, min_samples_leaf=4,\n",
       "                       splitter='random')"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_param = param_comb_train[np.argmax(succ)]\n",
    "print(\"Training success:\", np.max(succ))\n",
    "print(\"params: \", best_param)\n",
    "best_model = DecisionTreeClassifier(**best_param)\n",
    "# merge train and validation set, fit best paramater model\n",
    "Xtv = pd.concat([Xtrain, Xval])\n",
    "ytv = pd.concat([ytrain, yval])\n",
    "best_model.fit(Xtv, ytv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,1:]\n",
    "y = df.iloc[:,0]\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y, test_size=0.2, random_state=rd_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit model for generating missing values on Train+validation set, generate missing for evaluation and testing set.\n",
    "Xtrain is now Xtrain + Xvalidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pclass         200\n",
       "age            200\n",
       "sibsp          200\n",
       "parch          200\n",
       "fare           200\n",
       "name_length    200\n",
       "ranking        200\n",
       "sex_female     200\n",
       "sex_male       200\n",
       "embarked_C     200\n",
       "embarked_Q     200\n",
       "embarked_S     200\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "pclass         309\n",
       "age            309\n",
       "sibsp          309\n",
       "parch          309\n",
       "fare           309\n",
       "name_length    309\n",
       "ranking        309\n",
       "sex_female     309\n",
       "sex_male       309\n",
       "embarked_C     309\n",
       "embarked_Q     309\n",
       "embarked_S     309\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# fit missing model on bigger set - Train + validation\n",
    "missing_model = KNeighborsRegressor(**best_param_missing)\n",
    "X = Xtrain.copy(deep=True).dropna()\n",
    "# transform\n",
    "X = pd.DataFrame(scaler.fit_transform(X), index=X.index, columns=X.columns)\n",
    "# fit\n",
    "missing_model.fit(X.drop(columns='age'), X.age)\n",
    "# predict missing values for testing and evaluation\n",
    "Xt = Xtest[Xtest.age.isna()]\n",
    "Xt = pd.DataFrame(scaler.transform(Xt), index=Xt.index, columns=Xt.columns)\n",
    "Xeval = df_eval[df_eval.age.isna()]\n",
    "Xeval = pd.DataFrame(scaler.transform(Xeval), index=Xeval.index, columns=Xeval.columns)\n",
    "\n",
    "predictedTest = missing_model.predict(Xt.drop(columns='age'))\n",
    "predictedEval = missing_model.predict(Xeval.drop(columns='age'))\n",
    "cnt = 0\n",
    "for index, row in Xtest.iterrows():\n",
    "    if np.isnan(row['age']):\n",
    "        Xtest.at[index, 'age'] = predictedTest[cnt]\n",
    "        cnt += 1\n",
    "cnt = 0\n",
    "for index, row in df_eval.iterrows():\n",
    "    if np.isnan(row['age']):\n",
    "        df_eval.at[index, 'age'] = predictedEval[cnt]\n",
    "        cnt += 1\n",
    "\n",
    "# no missing data\n",
    "display(Xtest.notnull().sum(axis=0))\n",
    "display(df_eval.notnull().sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing accuracy:\", metrics.accuracy_score(ytest, best_model.predict(Xtest)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame()\n",
    "df_out.insert(0,'survived', best_model.predict(df_eval))\n",
    "df_out.insert(0,'ID',range(1000,1309))\n",
    "df_out.to_csv('results.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
